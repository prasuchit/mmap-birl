# mmap-birl

This project builds on the foundation established by J. Choi and K. Kim in MAP inference for Bayesian inverse reinforcement learning, NIPS 2010.

The algorithm developed in this repo considers occluded and noisy expert demonstrations and tries to learn the best reward function using Marginalized Maximum a Posteriori method with Bayesian IRL inference technique.

The codebase has been built and developed in python based on an existing repo by Jaedeug Choi (jdchoi@ai.kaist.ac.kr) in Matlab. 

The paper is available at this [link](https://arxiv.org/pdf/2109.07788). 

Cite this work as:

@article{suresh2021marginal,
  title={Marginal MAP Estimation for Inverse RL under Occlusion with Observer Noise},
  author={Suresh, Prasanth Sengadu and Doshi, Prashant},
  journal={arXiv preprint arXiv:2109.07788},
  year={2021}
}


Check out the following links for file specific readme:

1. [runner.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/runner-Readme.md)
2. [birl.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/birl-Readme.md)
3. [generator.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/generator-Readme.md)
4. [gridworld.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/gridworld-Readme.md)
5. [highway3.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/highway3-Readme.md)
6. [llh.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/llh-Readme.md)
7. [models.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/models-Readme.md)
8. [options.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/options-Readme.md)
9. [parameters.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/parameters-Readme.md)
10. [solver.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/solver-Readme.md)
11. [utils.py](https://github.com/prasuchit/mmap-irl/blob/master/Readme/utils-Readme.md)
