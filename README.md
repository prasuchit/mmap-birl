# mmap-irl

This project builds on the foundation established by J. Choi and K. Kim in MAP inference for Bayesian inverse reinforcement learning, NIPS 2010.

The algorithm developed in this repo considers occluded and noisy expert demonstrations and tries to learn the best reward function using Marginalized Maximum a Posteriori method with Bayesian IRL inference technique.

The codebase has been built upon an existing repo developed by [Lei Yang](https://github.com/yl-1993/SpectralMEIRL). Check out the following links for file specific readme:

1.) [Runner.py]()
